---
title: "Explainable AI Methods - A Brief Overview"
authors: "Andreas Holzinger, Anna Saranti, Christoph Molnar, Przemyslaw Biecek, Wojciech Samek"
collection: publications
permalink: /publication/2022-04-01-XAIsurv
hashtags: '<font color="purple">#Survey</font> <font color="#B5651D">#post-hoc</font>'
excerpt: 'This article provides a concise overview of 17 prominent methods in Explainable AI (xAI), aiming to familiarize beginners—particularly application engineers and data scientists—with the current state of the field. It summarizes techniques ranging from model-agnostic approaches like LIME and SHAP to specialized methods for visual, textual, and causal explanations.'
date: 2022-04-01
venue: 'xxAI - Beyond Explainable AI'
paperurl: 'https://link.springer.com/chapter/10.1007/978-3-031-04083-2_2'
---

Explainable Artificial Intelligence (xAI) is an established field with a vibrant community that has developed a variety of very successful approaches to explain and interpret predictions of complex machine learning models such as deep neural networks. In this article, we briefly introduce a few selected methods and discuss them in a short, clear and concise way. The goal of this article is to give beginners, especially application engineers and data scientists, a quick overview of the state of the art in this current topic. The following 17 methods are covered in this chapter: LIME, Anchors, GraphLIME, LRP, DTD, PDA, TCAV, XGNN, SHAP, ASV, Break-Down, Shapley Flow, Textual Explanations of Visual Models, Integrated Gradients, Causal Models, Meaningful Perturbations, and X-NeSyL.
