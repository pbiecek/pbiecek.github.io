---
title: "Swin SMT: Global Sequential Modeling for Enhancing 3D Medical Image Segmentation"
authors: "Maciej Chrabaszcz, Szymon Plotka, Przemyslaw Biecek"
collection: publications
permalink: /publication/2024-10-06-SwinSMT
hashtags: '<font color="#8B0000 red">#GenXAI</font> <font color="blue">#BioMed</font>'
excerpt: 'This paper presents Swin Soft Mixture Transformer (Swin SMT), a novel architecture that enhances 3D medical image segmentation by integrating a Soft Mixture-of-Experts mechanism into Swin UNETR to better capture diverse long-range dependencies. Evaluated on the TotalSegmentator-V2 dataset, Swin SMT achieves state-of-the-art performance with an average Dice Similarity Coefficient of 85.09%, while maintaining efficiency in both training and inference.'
date: 2024-10-06
venue: 'Medical Image Computing and Computer Assisted Intervention (MICCAI)'
paperurl: 'https://link.springer.com/chapter/10.1007/978-3-031-72111-3_65'
---

Recent advances in Vision Transformers (ViTs) have significantly enhanced medical image segmentation by facilitating the learning of global relationships. However, these methods face a notable challenge in capturing diverse local and global long-range sequential feature representations, particularly evident in whole-body CT (WBCT) scans. To overcome this limitation, we introduce Swin Soft Mixture Transformer (Swin SMT), a novel architecture based on Swin UNETR. This model incorporates a Soft Mixture-of-Experts (Soft MoE) to effectively handle complex and diverse long-range dependencies. The use of Soft MoE allows for scaling up model parameters maintaining a balance between computational complexity and segmentation performance in both training and inference modes. We evaluate Swin SMT on the publicly available TotalSegmentator-V2 dataset, which includes 117 major anatomical structures in WBCT images. Comprehensive experimental results demonstrate that Swin SMT outperforms several state-of-the-art methods in 3D anatomical structure segmentation, achieving an average Dice Similarity Coefficient of 85.09%. The code and pre-trained weights of Swin SMT are publicly available at https://github.com/MI2DataLab/SwinSMT.

